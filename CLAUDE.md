# Claude Development Guide

This guide helps AI assistants understand the AdCP project structure and maintain consistency when working on the codebase.

## Project Overview

The Advertising Context Protocol (AdCP) is an open standard for AI-powered advertising workflows. It provides a unified interface for media buying across diverse advertising platforms.

## Documentation Framework

**CRITICAL**: This project uses TWO documentation systems:

1. **Mintlify** - Primary documentation platform
   - All documentation in `docs/` directory
   - Markdown/MDX files served by Mintlify
   - Uses Mintlify-specific components (`<CodeGroup>`, not Docusaurus `<Tabs>`)
   - Run with: `mintlify dev` (should use conductor port, not 3000)

2. **Docusaurus** - Legacy/backwards compatibility only
   - Used for homepage (`server/public/index.html`)
   - Used to serve JSON schemas at `/schemas/` endpoints
   - Will be migrated away from eventually
   - DO NOT use Docusaurus components in documentation files

**When editing documentation:**
- ‚úÖ Use Mintlify `<CodeGroup>` for multi-language examples
- ‚ùå DO NOT use Docusaurus `import Tabs from '@theme/Tabs'`
- ‚ùå DO NOT use `<Tabs>` or `<TabItem>` components

## Documentation Locations

**Version-Specific Documentation** - Must be updated for each release:

1. **Release Announcement Locations** (update with each release):
   - `docs/intro.mdx` - Info banner at top of docs (lines 10-14)
   - `server/public/index.html` - Homepage structured data (lines 46-47: softwareVersion and releaseNotes)
   - `docs/reference/release-notes.mdx` - Detailed release notes with migration guide
   - `docs/reference/roadmap.mdx` - Roadmap showing shipped vs planned features

2. **Schema Version Documentation**:
   - `docs/reference/schema-versioning.mdx` - Explains `/schemas/v2.5/` and other version paths
   - `scripts/build-schemas.js` - Build output mentions schema-versioning.mdx (line 163)

3. **Repository Documentation**:
   - `README.md` - GitHub repository readme (not shown on website)
   - `CHANGELOG.md` - Auto-generated by changesets (DO NOT manually edit)

## Documentation Standards

### Protocol Specification vs Implementation

When working on documentation, it's crucial to maintain separation between:

1. **Protocol Specification** (what goes in docs/)
   - Abstract interface definitions
   - Tool signatures and parameters
   - Data models and schemas
   - Workflow descriptions
   - Platform-agnostic concepts

2. **Implementation Details** (what doesn't belong in the spec)
   - Database choices (PostgreSQL, MongoDB, etc.)
   - Deployment methods (Docker, Kubernetes, etc.)
   - Infrastructure details (multi-tenant architecture, etc.)
   - Specific technology stacks
   - Performance optimizations
   - Security implementation details

### Where Implementation Details Can Go

Implementation details can be mentioned as:
- **Recommendations** in a separate implementation guide
- **Examples** clearly marked as non-normative
- **Reference implementations** in the code
- **Best practices** documentation separate from the spec

### Writing Style

- Use "AdCP" not "ADCP"
- Focus on capabilities, not implementation
- Write for an audience implementing the protocol, not using a specific implementation
- Keep examples generic and illustrative

### Organization Naming - CRITICAL

**The organization name is "AgenticAdvertising.org" - NOT "Alliance for Agentic Advertising" or "AAO".**

**Rules:**
- ‚úÖ Use **AgenticAdvertising.org** in all user-facing content (emails, UI, documentation)
- ‚úÖ Use **agenticadvertising.org** for URLs and domain references
- ‚ùå DO NOT use "Alliance for Agentic Advertising"
- ‚ùå DO NOT use "AAO" or "AAO Team" (use "AgenticAdvertising.org Team")
- ‚ùå DO NOT use adcontextprotocol.org as the organization name (that's the protocol docs site)

**Why this matters:**
- AgenticAdvertising.org is the member organization/community
- AdCP (Ad Context Protocol) is the technical protocol specification
- These are related but distinct - members join AgenticAdvertising.org, they use AdCP

### Schema Compliance - CRITICAL RULE

**üö® ABSOLUTE REQUIREMENT: All documentation, code examples, and API usage MUST match the current JSON schemas exactly.**

**The schemas in `/static/schemas/v1/` are the SINGLE SOURCE OF TRUTH.**

**Rules:**
1. ‚ùå **NEVER document fields that don't exist in the schema**
2. ‚ùå **NEVER show examples using non-existent fields**
3. ‚ùå **NEVER mark schema-violating examples as `test=false` to "keep them around"**
4. ‚úÖ **ALWAYS verify fields exist in schema before documenting**
5. ‚úÖ **ALWAYS remove or fix examples that don't match schema**
6. ‚úÖ **ALWAYS update documentation when schemas change**

**If a field doesn't exist in the schema:**
- ‚ùå Don't document it "for future use"
- ‚ùå Don't mark examples as non-testable and keep them
- ‚úÖ **Remove the field from documentation entirely**
- ‚úÖ **Remove any examples showing that field**
- ‚úÖ If needed, file a schema issue to add the field properly

**Enforcement:**
- All testable pages MUST pass validation against current schemas
- No exceptions for "planned features" or "future fields"
- Examples violating schemas must be removed, not marked `test=false`

**How to verify schema compliance:**
```bash
# Check what fields exist in a schema
cat static/schemas/v1/core/creative-asset.json

# Test specific documentation file
npm test -- --file docs/media-buy/task-reference/sync_creatives.mdx

# Fields must exist in schema, not just in wishful thinking
```

### Testable Documentation

**IMPORTANT**: All code examples in documentation should be testable when possible.

**How to mark pages as testable**:

Add `testable: true` to the frontmatter of pages where all code examples should be tested:

```markdown
---
title: get_products
sidebar_position: 1
testable: true
---

# get_products

...code examples here (no test=true needed in individual blocks)...
```

**Key principles**:
1. **Page-level flag** - Use `testable: true` in frontmatter to mark entire page as testable
2. **Tab titles** - The text after the language becomes the tab title (e.g., "JavaScript", "Python", "CLI")
3. **Complete examples** - All code on testable pages must be complete and runnable
4. **Use test credentials** - Use the public test agent credentials in examples
5. **Schema compliance** - All examples must match current schemas exactly
6. **Error handling** - ALL examples must check discriminated union responses for errors before accessing success fields

**Supported languages**:
- `javascript` / `typescript` - Runs with Node.js ESM modules
- `python` - Runs with Python 3.11+
- `bash` - Supports `curl`, `npx`, and `uvx` commands

**What gets tested**:
- All code blocks on pages with `testable: true` frontmatter
- Code executes without errors
- API calls succeed (or fail as expected)
- Output matches expectations
- **Fields match current schemas**

**When NOT to mark page as testable**:
- Pages with incomplete code fragments
- Conceptual examples or pseudocode
- Browser-only code examples
- Code requiring user interaction
- Mixed testable and non-testable examples (use separate pages)

**Example testable page**:

```markdown
---
title: get_products
testable: true
---

# get_products

<CodeGroup>

\`\`\`javascript JavaScript
import { ADCPMultiAgentClient } from '@adcp/client';
const client = new ADCPMultiAgentClient([...]);
\`\`\`

\`\`\`python Python
from adcp import ADCPMultiAgentClient
\`\`\`

</CodeGroup>
```

**Running tests**:
```bash
node tests/snippet-validation.test.js
```

### Self-Describing JSON Examples with `$schema`

**IMPORTANT**: JSON examples in documentation should include `$schema` declarations for automated CI validation when they represent complete, schema-compliant objects.

**How it works**:
- JSON blocks with a `$schema` field are automatically validated against that schema in CI
- The test file `tests/json-schema-validation.test.js` discovers and validates all such blocks
- Validation runs as part of `npm test`

**When to add `$schema`**:
- ‚úÖ Complete error objects that match `/schemas/v2/core/error.json`
- ‚úÖ Complete product objects, creative manifests, media buys, etc.
- ‚úÖ Request/response examples that are fully formed
- ‚úÖ Any JSON that should conform to a published AdCP schema

**When NOT to add `$schema`**:
- ‚ùå Illustrative/simplified examples (e.g., channel guide format snippets)
- ‚ùå Fragments showing just a few fields
- ‚ùå Pseudocode or conceptual examples
- ‚ùå Examples with `...` placeholders or comments

**Example - Testable error object**:
```json
{
  "$schema": "https://adcontextprotocol.org/schemas/v2/core/error.json",
  "code": "INVALID_CREDENTIALS",
  "message": "API key is invalid or has been revoked",
  "details": {
    "provided_key": "ak_live_123..."
  }
}
```

**Key rule**: The `$schema` field MUST be the **first property** in the JSON object and MUST point to a valid schema URL.

**Schema URL pattern**: `https://adcontextprotocol.org/schemas/v2/{category}/{schema-name}.json`
- Categories: `core`, `media-buy`, `creative`, `signals`, `enums`
- Examples: `core/error.json`, `core/product.json`, `core/creative-manifest.json`

**Running JSON schema validation**:
```bash
# Run all tests including JSON schema validation
npm test

# Run only JSON schema validation
npm run test:json-schema
```

**Current coverage**: 45+ JSON blocks across documentation are validated against schemas.

### Discriminated Union Error Handling - CRITICAL PATTERN

**üö® ABSOLUTE REQUIREMENT: Always check for errors before accessing success fields in discriminated union responses.**

Many AdCP responses use discriminated unions with two variants:
1. **Success variant** - Has data fields (e.g., `creatives`, `products`, `packages`)
2. **Error variant** - Has `errors` array field

**The fields are mutually exclusive** - a response has EITHER success fields OR an `errors` field, never both.

**Required Pattern**:

**JavaScript:**
```javascript
const result = await testAgent.syncCreatives({...});

// ALWAYS check for errors first
if (result.errors) {
  console.error('Operation failed:', result.errors);
} else {
  // Safe to access success fields
  console.log(`Success: ${result.creatives.length} items`);
}
```

**Python:**
```python
result = await test_agent.simple.sync_creatives(...)

# ALWAYS check for errors first
if hasattr(result, 'errors') and result.errors:
    print('Operation failed:', result.errors)
else:
    # Safe to access success fields
    print(f"Success: {len(result.creatives)} items")
```

**Why This Matters:**
- Accessing `result.creatives` when `errors` is present = `undefined` (JS) or `AttributeError` (Python)
- Makes examples fail in confusing ways
- Hides the actual error from the user
- Violates schema contract

**Common Discriminated Union Responses:**
- `sync_creatives` - Either `creatives` OR `errors`
- `create_media_buy` - Either `media_buy_id` + `packages` OR `errors`
- `get_products` - Either `products` OR `errors`
- `list_creative_formats` - Either `formats` OR `errors`

**NEVER:**
‚ùå Access success fields without checking for errors first
‚ùå Assume the operation succeeded
‚ùå Write examples that will crash on error responses

**ALWAYS:**
‚úÖ Check for `errors` field first
‚úÖ Handle both success and error cases
‚úÖ Log errors clearly when they occur

## JSON Schema Maintenance

### Schema-Documentation Consistency

**GOLDEN RULE**: Documentation and JSON schemas MUST always be synchronized.

### Protocol vs Task Response Separation

**CRITICAL PRINCIPLE**: Task response schemas should contain ONLY domain-specific data. Protocol-level concerns are handled by the transport layer (MCP, A2A, REST).

**Protocol-level fields (DO NOT include in task responses)**:
- `message` - Human-readable summaries (handled by MCP content field, A2A assistant messages)
- `context_id` - Session/conversation tracking (handled by protocol)
- `task_id` - Async operation tracking (handled by protocol)
- `status` - Task state management (handled by protocol)
- `webhook_url` / `webhook_secret` - Callback configuration (handled by protocol)

**Task response fields (DO include)**:
- Domain-specific results (signals, creatives, products, delivery metrics)
- Operation-specific metadata (dry_run flag, estimated durations)
- Task-specific errors and warnings
- Resource identifiers (decisioning_platform_segment_id, platform_id, etc.)

**Example - What a task response should look like**:
```json
{
  "signals": [...],           // ‚úÖ Domain data
  "errors": [...]             // ‚úÖ Task-specific errors
}
```

**NOT like this**:
```json
{
  "message": "Found 3 signals",     // ‚ùå Protocol concern
  "context_id": "ctx_123",          // ‚ùå Protocol concern
  "task_id": "task_456",            // ‚ùå Protocol concern
  "status": "completed",            // ‚ùå Protocol concern
  "signals": [...]                  // ‚úÖ Domain data
}
```

This separation ensures AdCP tasks work identically across different protocol implementations (MCP, A2A, REST, future protocols).

**Protocol Envelope Schema**: The standard wrapper structure is documented in `/schemas/v1/core/protocol-envelope.json`. This schema shows how protocol layers wrap task response payloads with protocol-level fields.

### When to Update Schemas

Update JSON schemas whenever you:
- Add, remove, or rename any fields in task requests/responses
- Change field types, constraints, or validation rules
- Modify enum values (like status types, delivery types, etc.)
- Add new data models or modify existing core objects
- Change required vs optional field specifications

### Schema Update Checklist

When making documentation changes:
1. ‚úÖ Identify affected schemas in `static/schemas/v1/`
2. ‚úÖ Update request schemas (if changing task parameters)
3. ‚úÖ Update response schemas (if changing response structure)
4. ‚úÖ Update core data models (if changing object definitions)
5. ‚úÖ Update enum schemas (if changing allowed values)
6. ‚úÖ Verify cross-references (`$ref` links) are still valid
7. ‚úÖ Test schema validation with example data
8. ‚úÖ Update schema descriptions to match documentation

### Discriminated Union Types

**CRITICAL**: Always use explicit discriminator fields for union types to enable proper TypeScript type generation.

**Why Discriminators Matter:**
- **Without discriminators**: TypeScript generators produce index signatures (`{ [k: string]: unknown }`) or massive union types with poor type narrowing
- **With discriminators**: TypeScript produces proper discriminated unions with excellent IDE autocomplete and type safety
- **Impact**: Can reduce union signature count by 50%+ and eliminate broken type intersections

**Pattern to Use:**
```json
{
  "oneOf": [
    {
      "type": "object",
      "properties": {
        "discriminator_field": { "type": "string", "const": "variant_a" },
        "field_a": { "type": "string" }
      },
      "required": ["discriminator_field", "field_a"]
    },
    {
      "type": "object",
      "properties": {
        "discriminator_field": { "type": "string", "const": "variant_b" },
        "field_b": { "type": "number" }
      },
      "required": ["discriminator_field", "field_b"]
    }
  ]
}
```

**CRITICAL**: Always include explicit `"type"` before `"const"` in discriminator fields. This enables TypeScript generators to produce proper literal types (e.g., `Literal["variant_a"]`) instead of `Any`.

**Pattern to AVOID:**
```json
{
  "properties": { /* all fields optional */ },
  "allOf": [
    { "if": {...}, "then": {...} }  // ‚ùå TypeScript can't generate good types from this
  ]
}
```

**or:**
```json
{
  "properties": { /* shared fields */ },
  "oneOf": [
    { "required": ["field_a"] },
    { "required": ["field_b"] }
  ]
  // ‚ùå No discriminator means TypeScript can't narrow types
}
```

**Discriminator Field Requirements:**
- **ALWAYS** include explicit `"type"` declaration before `"const"` (e.g., `{ "type": "string", "const": "value" }`)
- Use semantic names that describe what's being discriminated
- Common patterns: `type`, `kind`, `delivery_type`, `output_format`, `asset_kind`
- Keep discriminator values lowercase with underscores
- Use string const values for strings, boolean const for booleans
- Match the `"type"` to the const value type (string, boolean, number, etc.)

**Examples from AdCP:**
- `destination.json`: `type: "platform" | "agent"`
- `sub-asset.json`: `asset_kind: "media" | "text"`
- `vast-asset.json`: `delivery_type: "url" | "inline"`
- `preview-render.json`: `output_format: "url" | "html" | "both"`

**When to Use:**
- ‚úÖ Object has mutually exclusive fields (either field_a OR field_b)
- ‚úÖ Different variants require different required fields
- ‚úÖ Schema will be used for TypeScript generation
- ‚úÖ Variants represent conceptually distinct alternatives

### Common Fields in Discriminated Unions

**CRITICAL**: When using `oneOf` for discriminated unions, always include common fields (like `ext`, `context`) **inside each variant**, not at the root level.

**Why This Matters:**
- **TypeScript Generation**: Root-level `properties` with `oneOf` creates intersection types (`Type1 & Type2`) which break Zod generation tools
- **Zod Compatibility**: Tools like `ts-to-zod` cannot convert intersections of discriminated unions to Zod schemas
- **Clean Types**: Including common fields in each variant produces clean union types that TypeScript can narrow properly
- **Maintainability**: Enables automatic Zod schema generation instead of manual schemas that can drift

**Pattern to Use:**
```json
{
  "oneOf": [
    {
      "type": "object",
      "properties": {
        "request_type": { "type": "string", "const": "single" },
        "data": { "type": "string" },
        "ext": { "$ref": "/schemas/core/ext.json" },
        "context": { "$ref": "/schemas/core/context.json" }
      },
      "required": ["request_type", "data"]
    },
    {
      "type": "object",
      "properties": {
        "request_type": { "type": "string", "const": "batch" },
        "items": { "type": "array" },
        "ext": { "$ref": "/schemas/core/ext.json" },
        "context": { "$ref": "/schemas/core/context.json" }
      },
      "required": ["request_type", "items"]
    }
  ]
}
```

**Pattern to AVOID:**
```json
{
  "oneOf": [
    {
      "properties": {
        "request_type": { "const": "single" },
        "data": { "type": "string" }
      }
    },
    {
      "properties": {
        "request_type": { "const": "batch" },
        "items": { "type": "array" }
      }
    }
  ],
  "properties": {
    "ext": { "$ref": "..." },      // ‚ùå Don't put common fields at root
    "context": { "$ref": "..." }   // ‚ùå This creates intersection types
  }
}
```

**Generated TypeScript - Good Pattern:**
```typescript
type Request =
  | { request_type: 'single', data: string, ext?: Ext, context?: Context }
  | { request_type: 'batch', items: any[], ext?: Ext, context?: Context };

// ‚úÖ Clean discriminated union
// ‚úÖ ts-to-zod can generate Zod schema automatically
// ‚úÖ Type narrowing works perfectly
```

**Generated TypeScript - Bad Pattern:**
```typescript
type Request = Request1 & Request2;

interface Request1 {
  ext?: Ext;
  context?: Context;
}

type Request2 =
  | { request_type: 'single', data: string }
  | { request_type: 'batch', items: any[] };

// ‚ùå Intersection type breaks Zod generation
// ‚ùå Requires manual Zod schema maintenance
// ‚ùå Confusing type structure
```

**Trade-offs:**
- **Pro**: Works with all TypeScript codegen tools automatically
- **Pro**: Enables automatic Zod generation
- **Pro**: Better developer experience
- **Con**: Minor duplication (repeating `$ref` in each variant)

The duplication is minimal since we use `$ref` - we're only repeating the reference, not the actual schema definition. The benefits far outweigh this small cost.

**Examples in AdCP:**
- ‚úÖ `preview-creative-request.json` - `ext` in each variant
- ‚úÖ `preview-creative-response.json` - `ext` in each variant
- ‚úÖ `sync-creatives-response.json` - `ext` in each variant

### Avoiding allOf with additionalProperties

Never use `allOf` when you need `additionalProperties: false`. JSON Schema's `additionalProperties` only sees properties in the **same schema object** - not from `$ref` or `allOf`. Properties from composed schemas get rejected as "additional".

**Solution**: Inline the base schema fields. Add a `$comment` noting which base schema was inlined.

**Example**: `create-media-buy-request.json` `reporting_webhook` inlines `push-notification-config.json` fields.

### Schema Location Map

- **Task Requests**: `static/schemas/v1/media-buy/` or `static/schemas/v1/signals/`
- **Core Objects**: `static/schemas/v1/core/`
- **Enums**: `static/schemas/v1/enums/` 
- **Registry**: `static/schemas/v1/index.json`

### Validation Testing

Always validate schemas work correctly:
```bash
# Use online JSON schema validators or
# Node.js with ajv library to test schemas
# Schemas are accessible locally at http://localhost:3000/schemas/v1/ when running npm run start
```

### Local Schema Access

When running `npm run start`, all JSON schemas are accessible at:
- Schema registry: `http://localhost:3000/schemas/v1/index.json`
- Core schemas: `http://localhost:3000/schemas/v1/core/{name}.json`
- Task schemas: `http://localhost:3000/schemas/v1/media-buy/{task}-{request|response}.json`
- Signal schemas: `http://localhost:3000/schemas/v1/signals/{task}-{request|response}.json`
- Enum schemas: `http://localhost:3000/schemas/v1/enums/{name}.json`

## Schema Versioning Workflow

### Path-Based Versioning

**IMPORTANT**: AdCP uses path-based versioning. The schema URL path indicates the version, not individual fields in schemas.

- **Version is in the path**: `/schemas/v1/` vs `/schemas/v2/`
- **No `adcp_version` field** in request or response schemas
- **Single source of truth**: `static/schemas/v1/index.json` contains the current version

**Rationale**:
- Eliminates redundant version fields in every schema
- Reduces maintenance burden (no need to update version in 30+ files)
- Clearer semantics (the schema you reference IS the version you use)
- Follows REST/HTTP conventions (version in path, not payload)

### Changesets: The Version Management System

**CRITICAL**: AdCP uses [Changesets](https://github.com/changesets/changesets) for version management. **NEVER manually update versions in `package.json` or `index.json`**.

**How it works:**
1. When making changes, create a changeset file in `.changeset/`
2. The changeset describes what changed and declares the version bump type (patch/minor/major)
3. When the PR is merged, the changeset automation:
   - Bumps `package.json` version
   - Updates `static/schemas/v1/index.json` `adcp_version` via sync script
   - Updates `CHANGELOG.md` with your changeset content
   - Creates a "Version Packages" PR

**Creating a changeset:**
```bash
# Interactive (won't work in non-interactive environments)
npx changeset

# Manual: Create .changeset/your-feature-name.md
---
"adcontextprotocol": minor
---

Brief description of what changed and why.
```

**Changeset types:**
- `patch` - Bug fixes to protocol/schemas, documentation updates that affect protocol understanding
- `minor` - New features, backward-compatible API/schema additions
- `major` - Breaking changes to APIs or schemas
- **empty** - Changes that don't affect the protocol (use `--empty` flag)

**When to use empty changesets:**
- Changes to CI/CD configuration
- Changes to test infrastructure
- Changes to development tools
- Internal refactoring that doesn't change the public API or schemas
- Documentation-only changes that don't affect functionality
- **Server/dashboard/UI changes** - The `server/` directory is implementation, not protocol
- Any changes that don't affect the AdCP protocol specification or schemas

```bash
# For changes that don't need a version bump
npx changeset add --empty
```

**Example changeset file (`.changeset/placement-targeting.md`):**
```markdown
---
"adcontextprotocol": minor
---

Add placement targeting for creative assignments. Enables products to define
multiple placements and buyers to assign different creatives to each placement.

**New schemas:**
- placement.json core schema
- Optional placements array in Product schema
- Optional placement_ids in CreativeAssignment schema
```

**What NOT to do:**
- ‚ùå Manually edit `package.json` version
- ‚ùå Manually edit `static/schemas/v1/index.json` `adcp_version`
- ‚ùå Manually edit `CHANGELOG.md`
- ‚ùå Run `npm run update-schema-versions` yourself (automation does this)

**What TO do:**
- ‚úÖ Create a changeset file describing your changes
- ‚úÖ Let the automation handle all version bumping
- ‚úÖ Update documentation and schema files as needed

### When to Version Schemas

AdCP uses semantic versioning for schemas. The changeset type determines the version bump:

**PATCH (1.0.0 ‚Üí 1.0.1)**: Schema fixes that don't change behavior
- Fix typos in descriptions
- Correct validation patterns
- Clarify existing field meanings
- Fix broken `$ref` links

**MINOR (1.0.0 ‚Üí 1.1.0)**: Backward-compatible additions
- Add new optional fields to requests/responses
- Add new enum values (append-only)
- Add new optional core object properties
- Add new tasks (new request/response pairs)

**MAJOR (1.0.0 ‚Üí 2.0.0)**: Breaking changes
- Remove or rename existing fields
- Change field types or constraints
- Make optional fields required
- Remove enum values
- Change existing field meanings

### Enum Versioning Strategy

**CRITICAL**: Enum changes follow strict semantic versioning rules to ensure SDK compatibility.

**Adding Enum Values (MINOR version):**
- ‚úÖ Adding new values to enums is **always a MINOR version bump**
- ‚úÖ Example: Adding `"svg"` to `asset-content-type.json` is MINOR
- ‚úÖ Rationale: Backward compatible - existing code continues to work
- ‚úÖ SDK impact: Old SDKs may not recognize new values, but won't break
- ‚úÖ Use case: Growing the protocol's capabilities over time

**Removing Enum Values (MAJOR version):**
- ‚ö†Ô∏è Removing enum values is **always a MAJOR version bump**
- ‚ö†Ô∏è Example: Removing `"radio"` from `property-type.json` is MAJOR
- ‚ö†Ô∏è Rationale: Breaking change - code using removed values will fail
- ‚ö†Ô∏è SDK impact: Clients using removed values will break
- ‚ö†Ô∏è Migration: Requires documenting replacement values or upgrade paths

**Renaming Enum Values (MAJOR version):**
- ‚ö†Ô∏è Renaming enum values is **always a MAJOR version bump**
- ‚ö†Ô∏è Example: Changing `"mobile_app"` to `"app"` in `property-type.json` is MAJOR
- ‚ö†Ô∏è Alternative: Add new value (MINOR), deprecate old value, remove in next MAJOR
- ‚ö†Ô∏è Rationale: Maintains compatibility during transition period

**Enum Evolution Example:**

```markdown
# v2.4.0 (MINOR) - Add new asset types
Added svg, json, and xml to asset-content-type enum.

# v2.5.0 (MINOR) - Deprecate old value
Added mobile_application to property-type enum.
Deprecated mobile_app (use mobile_application instead).

# v3.0.0 (MAJOR) - Remove deprecated value
Removed deprecated mobile_app from property-type enum.
Use mobile_application instead.
```

**Best Practices:**
- üìù Document enum additions in changeset with use cases
- üîç Search codebase for usage before removing values
- ‚è∞ Allow deprecation period (1-2 minor versions) before removal
- üìä Track usage metrics to inform deprecation decisions
- üö® Highlight enum removals prominently in release notes

### Schema Change Checklist

When making **ANY** schema change:

1. **‚úÖ Determine Version Impact**
   - Review changes against patch/minor/major criteria above
   - If breaking change, consider if really necessary
   - Document the rationale for the change

2. **‚úÖ Create a Changeset**
   - Create `.changeset/descriptive-name.md` with version bump type and description
   - **DO NOT** manually edit `package.json` or `index.json` versions

3. **‚úÖ Update All Related Schemas**
   - If changing core objects, update all schemas that reference them
   - If adding enum values, ensure all using schemas are compatible
   - Verify `$ref` links still resolve correctly

4. **‚úÖ Test Schema Changes**
   - Run `npm test` to validate all schemas
   - Test with real request/response examples
   - Ensure existing examples still validate

5. **‚úÖ Update Documentation**
   - Update all affected task documentation in `docs/`
   - Update API examples if needed
   - If major version, document migration path in changeset

### Example Schema Change Workflow

**Scenario:** Adding a new optional field to `create-media-buy-request.json`

**Step 1:** Make schema changes
```json
// In create-media-buy-request.json
{
  "$id": "/schemas/v1/media-buy/create-media-buy-request.json",
  "properties": {
    "new_optional_field": {
      "type": "string",
      "description": "New feature description"
    }
  }
}
```

**Step 2:** Create a changeset (`.changeset/add-new-field.md`)
```markdown
---
"adcontextprotocol": minor
---

Add optional `new_optional_field` parameter to create_media_buy request.

This enables [describe the feature and why it's needed].
```

**Step 3:** Commit and push
```bash
git add .
git commit -m "Add new_optional_field to create_media_buy"
git push
```

**What happens when merged:**
- Changesets bot sees the changeset file
- Automatically bumps version 2.2.0 ‚Üí 2.3.0
- Updates `index.json` `adcp_version` automatically
- Updates `CHANGELOG.md` with changeset content
- Creates a "Version Packages" PR

### Breaking Changes (Major Versions)

For major version changes:

1. **Create new version directory**: `static/schemas/v2/`
2. **Implement breaking changes** in v2 schemas
3. **Update schema registry** to include v2 paths
4. **Create migration documentation** with:
   - What changed and why
   - Step-by-step migration guide
   - Code examples for before/after
5. **Maintain v1 support** during transition period
6. **Deprecation timeline** for removing v1 support

## Release Notes

### Two Documentation Files

AdCP maintains two files for tracking changes:

1. **`CHANGELOG.md`** (root) - **Auto-generated by changesets**
   - Complete technical history with commit references
   - Automatically updated when changesets are consumed via `npm run version`
   - **DO NOT manually edit this file**

2. **`docs/reference/release-notes.md`** - **Manually written for users**
   - High-level "What's New" summaries
   - Migration guides with before/after code examples
   - Breaking changes prominently highlighted
   - Links to full CHANGELOG.md for technical details

### When to Update Release Notes

After each release (when changesets are consumed and Version Packages PR is merged):

1. **Review CHANGELOG.md** for the new version's changes
2. **Add a new section to docs/reference/release-notes.md** with:
   - Version number and release date
   - Link to full changelog: `[Full Changelog](https://github.com/adcontextprotocol/adcp/blob/main/CHANGELOG.md#230)`
   - "What's New" - High-level summary in plain language (1-3 paragraphs)
   - "Migration Guide" - Before/after code examples for key changes
   - "Breaking Changes" - Bulleted list of breaking changes

### Release Notes Format

```markdown
## Version X.Y.Z

**Released:** Month Year | [Full Changelog](link)

### What's New

High-level summary of the release theme and major features.
Use plain language that explains benefits and use cases.

### Migration Guide

**Before:**
\`\`\`json
{old code example}
\`\`\`

**After:**
\`\`\`json
{new code example}
\`\`\`

Brief explanation of what developers need to change.

### Breaking Changes

- Specific change with impact description
- Another breaking change
```

### Why This Approach

- **CHANGELOG.md** is machine-readable and complete but terse
- **Release notes** are human-readable and help developers understand impact
- Release notes are **manually written** because they require:
  - Plain language explanations of complex changes
  - Context about why changes were made
  - Code examples showing migration paths
  - Judgment about what's most important to highlight

Automation can't write good explanations or migration guides - that requires human understanding of the changes and their impact on developers.

## Local Development & Testing

### Testing the Website Locally with Docker

**PREFERRED METHOD**: Use Docker for local testing to avoid manual setup steps.

```bash
# Start postgres and the app with auto-migrations
docker compose up --build

# The app will be available at http://localhost:3000 (or your CONDUCTOR_PORT)
# Migrations run automatically on startup
```

This will:
1. Start a PostgreSQL container
2. Build and start the app container
3. Automatically run database migrations on startup
4. Expose the app on your configured port

**To reset the database:**
```bash
docker compose down -v  # -v removes the postgres volume
docker compose up --build
```

**To view logs:**
```bash
docker compose logs -f app      # App logs
docker compose logs -f postgres # Database logs
```

### Alternative: Local Development Without Docker

If you need to run without Docker (e.g., for faster iteration):

```bash
# 1. Ensure PostgreSQL is running locally and DATABASE_URL is set in .env.local

# 2. Run migrations manually
npm run db:migrate

# 3. Start the dev server
npm run start
```

### Environment Variables

Key environment variables for local development:
- `CONDUCTOR_PORT` - Port to run the server (default: 3000)
- `DATABASE_URL` - PostgreSQL connection string
- `RUN_MIGRATIONS=true` - Auto-run migrations on startup (used by Docker)

## Code Standards

### TypeScript/JavaScript
- Use TypeScript for all new code
- Follow existing patterns in the codebase
- Implement proper error handling
- Add types for all parameters and return values

### Testing
- Check for existing test patterns before writing new tests
- Run tests with `npm test` before committing
- Ensure new features have corresponding tests

### Design System - CRITICAL RULE

**üö® ABSOLUTE REQUIREMENT: All HTML files in `server/public/` MUST use the design system. No hardcoded colors.**

**Design System Location**: `/server/public/design-system.css`

**Required Import** (add to `<head>` of every HTML file):
```html
<link rel="stylesheet" href="/design-system.css">
```

**Prohibited Patterns:**
- ‚ùå **NEVER use hardcoded hex colors** (e.g., `color: #667eea;`, `background: #f5f5f5;`)
- ‚ùå **NEVER use hardcoded RGB/RGBA colors** (e.g., `rgba(0, 0, 0, 0.5)`)
- ‚ùå **NEVER define new color values** in inline styles or `<style>` blocks
- ‚ùå **NEVER use color names** (e.g., `color: gray;`, `background: white;`)

**Required Patterns:**
- ‚úÖ **ALWAYS use CSS custom properties** (e.g., `color: var(--color-brand);`)
- ‚úÖ **ALWAYS import design-system.css** before any custom styles
- ‚úÖ **ALWAYS use semantic variable names** that describe purpose, not appearance

**Color Variable Categories:**

| Category | Variables | Usage |
|----------|-----------|-------|
| Brand | `--color-brand`, `--color-brand-hover` | Primary brand colors, CTAs |
| Primary Scale | `--color-primary-50` to `--color-primary-900` | Tints and shades of brand |
| Gray Scale | `--color-gray-50` to `--color-gray-900` | Neutral backgrounds, borders |
| Text | `--color-text`, `--color-text-heading`, `--color-text-secondary`, `--color-text-muted` | Typography |
| Background | `--color-bg-page`, `--color-bg-card`, `--color-bg-subtle` | Page and component backgrounds |
| Border | `--color-border`, `--color-border-strong` | Dividers and outlines |
| Status | `--color-success-*`, `--color-warning-*`, `--color-error-*`, `--color-info-*` | Feedback colors |
| Overlay | `--color-surface-overlay` | Modal backdrops |

**Common Replacements:**

```css
/* Brand/Primary colors */
#667eea, #1a36b4, #764ba2  ‚Üí  var(--color-brand)

/* Text colors */
#333, #374151, #1a1a1a    ‚Üí  var(--color-text-heading)
#666, #6b7280             ‚Üí  var(--color-text-secondary)
#999, #9ca3af             ‚Üí  var(--color-text-muted)

/* Background colors */
#fff, #ffffff             ‚Üí  var(--color-bg-card)
#f5f5f5, #f9fafb          ‚Üí  var(--color-bg-page) or var(--color-bg-subtle)

/* Border colors */
#e5e7eb, #e0e0e0, #ddd    ‚Üí  var(--color-border)

/* Status colors */
#c33, #dc2626, #ef4444    ‚Üí  var(--color-error-600) or var(--color-error-500)
#10b981, #059669          ‚Üí  var(--color-success-500) or var(--color-success-600)
#f90, #f59e0b             ‚Üí  var(--color-warning-500)
#3b82f6                   ‚Üí  var(--color-info-500)

/* Overlays */
rgba(0,0,0,0.5)           ‚Üí  var(--color-surface-overlay)
```

**JavaScript Template Literals:**
When generating HTML in JavaScript, use CSS variables the same way:
```javascript
// ‚úÖ CORRECT
const html = `<div style="color: var(--color-text-heading); background: var(--color-bg-card);">...</div>`;

// ‚ùå WRONG
const html = `<div style="color: #333; background: #fff;">...</div>`;
```

**Verification:**
After editing any HTML file, run this grep to ensure no hardcoded colors remain:
```bash
grep -E '#[0-9a-fA-F]{3,6}' server/public/your-file.html
```

### Format Field Naming Convention

**CRITICAL**: Always use consistent naming for format-related fields to avoid developer confusion.

**Established Convention**:
- **`"formats"`** = Array of format objects (with full details like name, type, requirements, assets_required, etc.)
- **`"format_ids"`** = Array of format ID strings (references to format objects)
- **`"format_types"`** = Array of high-level type strings (video, display, audio, native, etc.)

**Examples**:
```json
// ‚úÖ CORRECT - list_creative_formats response (format objects)
{
  "formats": [
    {
      "format_id": "video_standard_30s",
      "name": "Standard Video - 30 seconds", 
      "type": "video",
      "requirements": {...}
    }
  ]
}

// ‚úÖ CORRECT - Product response (format ID strings)
{
  "product_id": "ctv_premium",
  "format_ids": ["video_standard_30s", "video_standard_15s"]
}

// ‚úÖ CORRECT - get_products filter (high-level types)
{
  "filters": {
    "format_types": ["video", "display"]
  }
}
```

**When adding new fields**:
- Use `format_ids` when referencing existing formats by ID
- Use `formats` only when returning full format objects
- Use `format_types` for broad categorical filtering
- Never use `formats` for arrays of strings - always use `format_ids`

**Schema Validation**: All schemas must follow this convention. Tests will fail if format fields don't match the expected naming pattern.

### Format ID Structure

**CRITICAL**: Format IDs are ALWAYS structured objects, never strings, to avoid parsing ambiguity and handle namespace collisions.

**Structured Format ID (REQUIRED EVERYWHERE)**:
```json
{
  "agent_url": "https://creatives.adcontextprotocol.org",
  "id": "display_300x250"
}
```

**Where structured format IDs are used (everywhere)**:
- **All request parameters** accepting format_id (sync_creatives, build_creative, preview_creative, etc.)
- **All response fields** containing format_id (list_creatives, get_products, list_creative_formats, etc.)
- **Creative asset objects** specifying which format they conform to
- **Product responses** listing supported formats
- **Filter parameters** in list operations (format_ids plural = array of objects)
- **Creative manifests** specifying the format

**Why structured objects everywhere?**
- No parsing ambiguity - components are explicit
- Handles format ID collisions between different creative agents
- Simpler mental model - one pattern, no exceptions
- Future-proof for versioning and extensions

**Schema reference**:
```json
{
  "format_id": {
    "$ref": "/schemas/v1/core/format-id.json"
  }
}
```

**Validation rule**: All AdCP agents MUST reject string format_ids in ALL contexts with clear error messages. No exceptions.

**Legacy handling**: If supporting legacy clients sending strings, you MAY auto-upgrade during a deprecation period (max 6 months), but MUST log warnings and fail on unknown format strings. Recommended approach is strict rejection from day one.

### Structured Rendering Dimensions

**IMPORTANT**: Visual formats (display, dooh, native) use structured dimensions within the `renders` array instead of string-based dimensions.

**Schema structure** (formats have `renders` array):
```json
{
  "format_id": {...},
  "type": "display",
  "renders": [
    {
      "role": "primary",
      "dimensions": {
        "width": 300,
        "height": 250,
        "responsive": {
          "width": false,
          "height": false
        },
        "unit": "px"
      }
    }
  ]
}
```

**Why the renders structure:**
- Supports single and multi-render formats uniformly (companion ads, adaptive formats)
- Eliminates string parsing ("300x250" ‚Üí structured object)
- Schema-validated with proper typing
- Supports responsive dimensions (min/max width/height)
- Supports aspect ratio constraints
- Enables physical units for DOOH (inches, cm)
- Proper preview rendering without custom parsing
- Clear semantic roles for each rendered piece (primary, companion, mobile_variant, etc.)

**Migration from string dimensions:**
- Old: `"dimensions": "300x250"` (string in requirements)
- New: `"renders": [{"role": "primary", "dimensions": {width: 300, height: 250, responsive: {width: false, height: false}, unit: "px"}}]`

### Multi-Render Preview Support

**IMPORTANT**: Preview responses now support multiple rendered pieces per variant (companion ads, multi-placement formats).

**Schema structure** (`preview-creative-response.json`):
```json
{
  "previews": [{
    "preview_id": "variant_1",
    "renders": [{
      "render_id": "primary_video",
      "preview_url": "https://...",
      "role": "primary",
      "dimensions": {"width": 1920, "height": 1080}
    }, {
      "render_id": "companion_banner",
      "preview_url": "https://...",
      "role": "companion",
      "dimensions": {"width": 300, "height": 250}
    }]
  }]
}
```

**Why multi-render previews:**
- Companion ads (video + display banner)
- Adaptive formats (desktop/mobile/tablet variants)
- Multi-placement formats (multiple sizes from one creative)
- DOOH installations (multiple screens)

**Key insight**: All renders are from the SAME format (e.g., `video_with_companion_300x250`). The format specification defines multiple rendered pieces. Each render includes `dimensions` for iframe sizing.

**Terminology**: Use "renders" not "outputs" to avoid confusion with `output_format_ids` in generative creative formats.

### Removed Format Fields

**IMPORTANT**: The following fields have been removed from the format schema and should NOT be used:

#### `accepts_3p_tags` (Removed in v1.9.0)
- **Why removed**: Redundant with HTML and JavaScript asset types
- **Migration**: Filter formats by `asset_types: ["html"]` or `asset_types: ["javascript"]` to find formats that accept third-party tags
- **Rationale**: Third-party tags ARE HTML/JavaScript assets. If a format accepts these asset types, it implicitly supports third-party tags.

#### `category` and `is_standard` (Removed in v1.10.0)
- **Why removed**: Information is redundant with source location
- **Migration**:
  - Standard formats are defined in the creative-agent repository
  - Custom formats have an `agent_url` pointing to a non-standard creative agent
  - Format location/source already indicates whether it's standard or custom
- **Rationale**: These fields carried information already expressed by the format's authoritative source. Adding explicit fields was redundant and increased maintenance burden.

#### `preview_image` (Deprecated in v2.5.0, will be removed in v3.0.0)
- **Why deprecated**: Static image URLs lack flexibility for rich card presentations
- **Migration**: Use `format_card` and optionally `format_card_detailed` fields instead
  - `format_card` provides structured card definition with format_id and manifest
  - Supports dynamic generation via `preview_creative` or pre-rendered CDN assets
  - Detailed cards enable carousel + markdown specs for comprehensive format documentation
- **Backward compatibility**: Field remains functional but should not be used in new implementations
- **Rationale**: Card system uses AdCP's own creative format infrastructure for extensibility and consistency

## Common Tasks

### Before Making Changes
1. Check `git status` to understand current state
2. Read relevant existing documentation
3. Search for similar patterns in the codebase
4. Consider impact on other parts of the system

### Documentation Updates
1. Keep protocol spec abstract and implementation-agnostic
2. Update all related documentation when making changes
3. Ensure examples are consistent across docs
4. Remove version numbers while in v1 development
5. **CRITICAL: JSON Schema Synchronization**
   - When changing any task parameters, data models, or field definitions in docs, **ALWAYS update the corresponding JSON schemas** in `static/schemas/v1/`
   - When updating JSON schemas, **ALWAYS verify the documentation matches** the schema definitions
   - Check both request/response schemas AND core data model schemas for affected changes
   - Update the schema registry (`static/schemas/v1/index.json`) if adding/removing schemas

### Code Changes
1. Follow existing patterns
2. Update tests
3. Run linting: `npm run lint`
4. Run type checking: `npm run typecheck`
5. Run tests: `npm test`

## Key Concepts to Remember

### Protocol Design Principles
1. **MCP-Based**: Built on Model Context Protocol
2. **Asynchronous**: Operations may take time
3. **Human-in-the-Loop**: Optional manual approval
4. **Platform Agnostic**: Works across ad platforms
5. **AI-Optimized**: Designed for AI agents

### What Exists vs What Doesn't
- ‚úÖ `get_products` - discovers inventory
- ‚ùå `discover_products` - doesn't exist
- ‚ùå `get_avails` - removed in favor of direct purchase
- ‚úÖ `create_media_buy` - creates campaigns
- ‚úÖ `list_creative_formats` - shows supported formats

### Data Models
- Products don't include `targeting_template` or `implementation_config` in responses
- Focus on what's visible to API consumers, not internal implementation

## Useful Commands

```bash
# Development
npm run dev          # Start development server
npm run build        # Build the project
npm test            # Run tests
npm run lint        # Check code style
npm run typecheck   # Check TypeScript types

# Documentation
npm run docs:dev    # Start docs dev server
npm run docs:build  # Build documentation

# Git
git status          # Check current changes
git add -A          # Stage all changes
git commit -m "..."  # Commit with message
git push            # Push to remote
```

## When in Doubt

1. Check existing code for patterns
2. Keep the specification abstract
3. Focus on protocol capabilities, not implementation
4. Ask for clarification on design decisions
5. Refer to the [Task Reference](docs/media-buy/task-reference/index.mdx) for tool signatures

## Standard Formats: Lessons Learned

### Schema Simplification Best Practices

Through the standard formats implementation, we've learned key principles for schema design:

1. **Remove Platform-Specific Complexity**
   - Formats should be platform-agnostic
   - No `platform` or `placement_type` fields in format definitions
   - Publishers adapt formats through placement, not specification changes

2. **Simplify Selection Logic**
   - Removed complex `format-selection.json` schema
   - No placement types or format preferences in products
   - Buyers directly specify formats they want to provide

3. **Clear Asset Identification**
   - Added `asset_role` field to identify asset purposes (e.g., 'hero_image', 'logo')
   - Assets are self-describing with clear roles
   - Enables better creative assembly and validation

4. **Better Field Naming**
   - `accepts_3p_tags` instead of `is_3p_served` (indicates optionality)
   - `format_ids` instead of ambiguous or verbose alternatives (clear and consistent)
   - Field names should indicate purpose, not state

### Testing Considerations

1. **Schema Registry Tests**
   - Not all schemas need to be in the registry
   - Registry only needs to reference core and enum schemas
   - Standard format schemas are discovered through directory structure
   - Test should validate registry references exist, not that all schemas are registered

2. **Schema Validation Patterns**
   - Include `index.json` files in schema discovery
   - Validate examples match schema structure
   - Ensure all `$ref` links resolve correctly
   - Test both request and response schemas

### Code Review Integration

When addressing code review feedback:

1. **Use Todo Lists**
   - Create a todo for each review comment
   - Track progress systematically
   - Mark items complete as you address them

2. **Batch Related Changes**
   - Group similar schema updates together
   - Use MultiEdit for multiple changes to same file
   - Test after each batch of changes

3. **Documentation Sync**
   - Update documentation when changing schemas
   - Keep examples consistent with schema changes
   - Update both spec docs and CLAUDE.md as needed

### Standard Formats Architecture

Standard creative formats are maintained in the separate **creative-agent repository**, not in this protocol specification repo.

Key principles:
- Each format is self-contained with all requirements
- No cross-references to placement or selection schemas
- Assets are defined inline with clear specifications
- Format categories match industry standards (display, video, native, etc.)
- The reference creative agent at `https://creative.adcontextprotocol.org` serves these formats

## Documentation Structure Theory & Learnings

### Core Documentation Principles

Based on extensive reorganization of the AdCP documentation, these principles have emerged as critical for effective technical documentation:

#### 1. **User-Centric Organization**
- Structure docs around **user workflows**, not internal system architecture
- Group related concepts together even if they map to different technical components
- Prioritize **what users need to accomplish** over how the system is built internally

#### 2. **Eliminate Redundancy Ruthlessly**
- **One source of truth** for each concept - never duplicate content across multiple files
- Use **cross-references** rather than copying content
- When consolidating, choose the **most logical location** based on user workflow

#### 3. **Consistent Naming Patterns**
- Use **"Overview"** for index pages rather than repeating the section name
- Examples: `capability-discovery/index.md` titled "Overview", not "Capability Discovery"
- Avoid navigation hierarchies where the same name appears twice

#### 4. **Protocol-Agnostic Documentation**
- **Never** assume a specific protocol (MCP, A2A, REST) in core documentation
- Focus on **tasks and capabilities**, not transport mechanisms
- Reference protocol-specific details in dedicated protocol sections

#### 5. **Workflow-Based Information Architecture**
- Organize by **user journey stages**: Discovery ‚Üí Planning ‚Üí Execution ‚Üí Optimization
- Group related activities together (e.g., Policy Compliance belongs with Media Buys, not as standalone)
- Separate **conceptual understanding** from **technical implementation**

### Documentation Architecture Lessons

#### Multi-Level Navigation Strategy
```
Main Section (e.g., "Media Buy")
‚îú‚îÄ‚îÄ Overview (introduces the domain)
‚îú‚îÄ‚îÄ Foundation Concepts (e.g., Capability Discovery)
‚îú‚îÄ‚îÄ Planning Activities (e.g., Product Discovery)  
‚îú‚îÄ‚îÄ Execution Workflows (e.g., Media Buys, Creatives)
‚îî‚îÄ‚îÄ Advanced Topics (technical deep-dives)
```

#### Content Consolidation Guidelines

**When to Consolidate:**
- Content serves the **same user workflow**
- Information is **closely related** conceptually
- Separate documents create **cognitive overhead**
- Users would naturally expect to find information together

**When to Keep Separate:**
- Content serves **different audiences** (conceptual vs. technical)
- Documents are **reference material** (e.g., API docs)
- Content has **different lifecycles** (e.g., stable concepts vs. evolving examples)

#### Navigation Best Practices

1. **Role-Based Getting Started**
   - Provide **multiple entry points** based on user role
   - "For AI Agent Developers", "For Campaign Managers", "For Publishers"
   - Each path references the **same underlying documentation** but suggests different reading order

2. **Clear Section Purposes**
   - **Capability Discovery**: Foundation concepts and requirements
   - **Product Discovery**: Natural language inventory search
   - **Media Buys**: Campaign lifecycle and execution
   - **Creatives**: Asset management workflows
   - **Advanced Topics**: Technical implementation details

3. **Avoid Deep Nesting**
   - Maximum **3 levels** of navigation hierarchy
   - Use **in-page sections** rather than additional file levels
   - Prefer **longer comprehensive pages** over many small pages

### Anti-Patterns to Avoid

#### 1. **Technology-Centric Organization**
```
‚ùå BAD: Organized by tech stack
‚îú‚îÄ‚îÄ MCP Integration
‚îú‚îÄ‚îÄ A2A Integration  
‚îú‚îÄ‚îÄ Database Schemas
‚îî‚îÄ‚îÄ API Endpoints

‚úÖ GOOD: Organized by user workflow
‚îú‚îÄ‚îÄ Discovery & Planning
‚îú‚îÄ‚îÄ Campaign Execution
‚îú‚îÄ‚îÄ Performance Optimization
‚îî‚îÄ‚îÄ Technical Implementation
```

#### 2. **Redundant Section Titles**
```
‚ùå BAD: Navigation shows duplicate names
Product Discovery
‚îú‚îÄ‚îÄ Product Discovery (redundant!)
‚îú‚îÄ‚îÄ Brief Expectations
‚îî‚îÄ‚îÄ Example Briefs

‚úÖ GOOD: Clear hierarchy
Product Discovery  
‚îú‚îÄ‚îÄ Overview
‚îú‚îÄ‚îÄ Brief Expectations
‚îî‚îÄ‚îÄ Example Briefs
```

#### 3. **Protocol Assumptions**
```
‚ùå BAD: MCP-centric language
"Use MCP tool calls to discover products..."

‚úÖ GOOD: Protocol-agnostic language  
"Use the get_products task to discover products..."
```

#### 4. **Scattered Related Content**
```
‚ùå BAD: Related concepts separated
‚îú‚îÄ‚îÄ Media Buys (lifecycle)
‚îú‚îÄ‚îÄ Policy Compliance (standalone)
‚îî‚îÄ‚îÄ Optimization (separate section)

‚úÖ GOOD: Workflow-grouped content
‚îî‚îÄ‚îÄ Media Buys
    ‚îú‚îÄ‚îÄ Lifecycle
    ‚îú‚îÄ‚îÄ Policy Compliance  
    ‚îî‚îÄ‚îÄ Optimization & Reporting
```

### Specific AdCP Learnings

#### 1. **Brief-Based Targeting Philosophy**
- Documentation should emphasize **natural language approach** over technical targeting APIs
- Focus on **publisher expertise** and **inclusive pricing** concepts
- Technical overlays are **exception cases**, not the primary workflow

#### 2. **Separation of Concerns Model**
- The **three-role model** (Publisher, Principal, Orchestrator) is central to AdCP
- This model should be explained in **Media Buy context**, not as general protocol theory
- Each role has **different documentation needs** and entry points

#### 3. **Asynchronous-First Design**
- Emphasize **"timely but not real-time"** nature throughout documentation
- Response time expectations should be **clearly communicated** early
- Human-in-the-loop workflows are **normal**, not edge cases

#### 4. **Multi-Protocol Reality**
- AdCP **tasks are protocol-agnostic** - the same 8 tasks work across MCP, A2A, and future protocols
- Protocol choice is an **integration decision**, not a capability limitation
- Documentation should **guide protocol selection** based on use case, not assume one

### Continuous Improvement Guidelines

1. **Regular User Journey Reviews**
   - Periodically trace through documentation **as different user types**
   - Identify **friction points** and **missing connections**
   - Consolidate or separate content based on **actual usage patterns**

2. **Cross-Reference Validation**
   - Ensure all **internal links** remain valid after reorganization
   - Use **relative paths** that survive structural changes
   - Regularly test **build process** to catch broken references

3. **Content Lifecycle Management**
   - Mark **outdated concepts** for removal rather than updating indefinitely
   - **Archive rather than delete** content that may become relevant again
   - Keep **CLAUDE.md updated** with structural decisions and rationale

These principles emerged from reorganizing 50+ documentation files and should guide future structural decisions. The goal is always **user success** - helping people accomplish their goals with minimal cognitive overhead.